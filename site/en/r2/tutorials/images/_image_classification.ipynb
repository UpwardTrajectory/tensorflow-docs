{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBFXQGKYUc4X"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "1z4xy2gTUc4a"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FE7KNzPPVrVV"
   },
   "source": [
    "# Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwQtSOz0VrVX"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/beta/images/image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/images/image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/images/image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gN7G9GFmVrVY"
   },
   "source": [
    "This tutorial shows how to classify cats or dogs from images. It builds an image classifier using a `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`. You will get some practical experience and develop intuition for the following concepts:\n",
    "\n",
    "* Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class to efficiently work with data on disk to use with the model.\n",
    "* _Overfitting_ —How to identify and prevent it.\n",
    "* _Data augmentation_ and _dropout_ —Key techniques to fight overfitting in computer vision tasks to incorporate into the data pipeline and image classifier model.\n",
    "\n",
    "This tutorial follows a basic machine learning workflow:\n",
    "\n",
    "1. Examine and understand data\n",
    "2. Build an input pipeline\n",
    "3. Build the model\n",
    "4. Train the model\n",
    "5. Test the model\n",
    "6. Improve the model and repeat the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VddxeYBEVrVZ"
   },
   "source": [
    "Let's start by importing the required packages. The `os` package is used to read files and directory structure, NumPy is used to convert python list to numpy array and to perform required matrix operations and `matplotlib.pyplot` to plot the graph and display images in the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtPGh2MAVrVa"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TI3XEQuJVrVd"
   },
   "source": [
    "This tutorial uses data available as `.zip` archive file. Use the `zipfile` module to extract its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19eGwtQ4VrVe"
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jlchl4x2VrVg"
   },
   "source": [
    "Import Tensorflow and the Keras classes needed to construct our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Homebrew...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 3 taps (homebrew/core, homebrew/cask and caskroom/versions).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "cjson                                    procs\n",
      "clojure-lsp                              scala@2.12\n",
      "docker-machine-driver-vmware             scdoc\n",
      "drone-cli                                swig@3\n",
      "dust                                     termshark\n",
      "hey                                      terraformer\n",
      "ipopt                                    virgil\n",
      "newman\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Formulae\u001b[0m\n",
      "\u001b[1mopenssl \u001b[32m✔\u001b[0m\u001b[0m                                latex2html\n",
      "\u001b[1msbcl \u001b[32m✔\u001b[0m\u001b[0m                                   ledger\n",
      "akamai                                   lgogdownloader\n",
      "angular-cli                              libbitcoin\n",
      "ansible                                  libbitcoin-blockchain\n",
      "anyenv                                   libbitcoin-client\n",
      "arangodb                                 libbitcoin-database\n",
      "aravis                                   libbitcoin-explorer\n",
      "armadillo                                libbitcoin-network\n",
      "ask-cli                                  libbitcoin-node\n",
      "atlantis                                 libbitcoin-protocol\n",
      "autorest                                 libbitcoin-server\n",
      "avro-cpp                                 libical\n",
      "aws-sdk-cpp                              libosinfo\n",
      "awscli                                   libpulsar\n",
      "azure-cli                                librealsense\n",
      "azure-storage-cpp                        libsigc++\n",
      "bazel                                    libswiften\n",
      "bit                                      libtorrent-rasterbar\n",
      "bitcoin                                  libvirt\n",
      "bitrise                                  linkerd\n",
      "bitwarden-cli                            lmod\n",
      "boost                                    macvim\n",
      "boost-bcp                                mame\n",
      "boost-build                              mariadb-connector-c\n",
      "boost-mpi                                maxima\n",
      "boost-python                             mercurial\n",
      "boost-python3                            mesa\n",
      "braid                                    metaproxy\n",
      "buildifier                               micronaut\n",
      "caffe                                    mighttpd2\n",
      "calicoctl                                minio\n",
      "certbot                                  minio-mc\n",
      "cfn-lint                                 mk-configure\n",
      "cgal                                     mksh\n",
      "chakra                                   mkvtoolnix\n",
      "circleci                                 molecule\n",
      "citus                                    monero\n",
      "clojure                                  monetdb\n",
      "cointop                                  mpich\n",
      "composer                                 nativefier\n",
      "conan                                    nats-streaming-server\n",
      "convox                                   ncmpcpp\n",
      "cpprestsdk                               nim\n",
      "cromwell                                 node\n",
      "cryfs                                    node-build\n",
      "crystal                                  node_exporter\n",
      "cucumber-cpp                             nomad\n",
      "curl                                     opa\n",
      "curl-openssl                             openimageio\n",
      "cython                                   osquery\n",
      "deno                                     osrm-backend\n",
      "dependency-check                         paket\n",
      "dhall                                    pam-u2f\n",
      "django-completion                        pandoc\n",
      "dnscrypt-proxy                           payara\n",
      "doctl                                    pgrouting\n",
      "duck                                     php-cs-fixer\n",
      "duo_unix                                 phpmyadmin\n",
      "encfs                                    phpunit\n",
      "envconsul                                plantuml\n",
      "erlang                                   pod2man\n",
      "erlang@21                                pre-commit\n",
      "exiftool                                 prettier\n",
      "exploitdb                                proteinortho\n",
      "firebase-cli                             prototool\n",
      "flow                                     pstoedit\n",
      "fn                                       pulumi\n",
      "folly                                    pybind11\n",
      "fontforge                                pyenv\n",
      "fselect                                  quicktype\n",
      "fuseki                                   rbspy\n",
      "futhark                                  rke\n",
      "gdcm                                     scala\n",
      "gengetopt                                scalariform\n",
      "geoipupdate                              scons\n",
      "gibo                                     scrcpy\n",
      "git                                      serverless\n",
      "git-remote-hg                            sfcgal\n",
      "git-town                                 shadowsocks-libev\n",
      "gitlab-runner                            ship\n",
      "gitleaks                                 skaffold\n",
      "glib                                     solr@7.7\n",
      "glib-networking                          sops\n",
      "glooctl                                  source-highlight\n",
      "gmic                                     sphinx-doc\n",
      "gnu-units                                sslsplit\n",
      "gnumeric                                 telegraf\n",
      "gnunet                                   teleport\n",
      "gnuradio                                 terraform\n",
      "go                                       terragrunt\n",
      "godep                                    terrahub\n",
      "goffice                                  tfenv\n",
      "golang-migrate                           thefuck\n",
      "goofys                                   tile38\n",
      "goreleaser                               tokei\n",
      "gpsbabel                                 tomcat\n",
      "grafana                                  topgrade\n",
      "grakn                                    tox\n",
      "graph-tool                               u-boot-tools\n",
      "grpc                                     uhd\n",
      "gst-plugins-good                         upscaledb\n",
      "helmfile                                 v8\n",
      "hlint                                    vala\n",
      "hyperfine                                vault\n",
      "i2pd                                     vim\n",
      "icecream                                 vultr\n",
      "imagemagick                              webpack\n",
      "imagemagick@6                            weechat\n",
      "inlets                                   wesnoth\n",
      "istioctl                                 whois\n",
      "itk                                      widelands\n",
      "jdupes                                   wildfly-as\n",
      "jenkins                                  wimlib\n",
      "jenkins-lts                              wtf\n",
      "jfrog-cli-go                             xonsh\n",
      "jhipster                                 yamllint\n",
      "joplin                                   yelp-tools\n",
      "jsonnet                                  ykman\n",
      "juju                                     you-get\n",
      "knot                                     youtube-dl\n",
      "kubernetes-cli                           yubico-piv-tool\n",
      "kubernetes-helm                          z3\n",
      "kubernetes-service-catalog-client        zim\n",
      "lasi                                     zlog\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRenamed Formulae\u001b[0m\n",
      "gnatsd -> nats-server\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDeleted Formulae\u001b[0m\n",
      "scala@2.10                               swig@3.04\n",
      "\n",
      "\u001b[31mError:\u001b[0m wget 1.20.2 is already installed\n",
      "To upgrade to 1.20.3_1, run `brew upgrade wget`.\n",
      "\u001b[34m==>\u001b[0m \u001b[1m`brew cleanup` has not been run in 30 days, running now...\u001b[0m\n",
      "Removing: /Users/dakaspar/Library/Caches/Homebrew/freetds--1.1.5.mojave.bottle.tar.gz... (3.0MB)\n",
      "Removing: /Users/dakaspar/Library/Caches/Homebrew/libidn2--2.1.1a.mojave.bottle.tar.gz... (222KB)\n",
      "Removing: /Users/dakaspar/Library/Caches/Homebrew/openssl--1.0.2r.mojave.bottle.tar.gz... (3.7MB)\n",
      "Removing: /Users/dakaspar/Library/Caches/Homebrew/postgresql--11.2_1.mojave.bottle.tar.gz... (10MB)\n",
      "Removing: /Users/dakaspar/Library/Caches/Homebrew/sbcl--1.5.2.mojave.bottle.tar.gz... (15.9MB)\n",
      "Removing: /Users/dakaspar/Library/Caches/Homebrew/Cask/chromedriver--74.0.3729.6.zip... (6.7MB)\n",
      "Removing: /Users/dakaspar/Library/Caches/Homebrew/Cask/dbeaver-community--6.0.4.dmg... (55.2MB)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/pgloader... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/libtool... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/postgresql... (1.2KB)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/python@2... (3 files, 128.4KB)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/gdbm... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/icu4c... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/readline... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/sqlite... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/unixodbc... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/mongodb... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/geckodriver... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/freetds... (64B)\n",
      "Removing: /Users/dakaspar/Library/Logs/Homebrew/sbcl... (64B)\n",
      "Collecting wrapt\n",
      "Installing collected packages: wrapt\n",
      "Successfully installed wrapt-1.11.1\n",
      "Requirement already satisfied: tensorflow==2.0.0-beta0 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (2.0.0b0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (3.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.12.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.16.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (0.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.11.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (0.7.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.0.9)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.16.4)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (0.33.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (0.1.7)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tensorflow==2.0.0-beta0) (1.0.7)\n",
      "Requirement already satisfied: setuptools in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta0) (41.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (0.15.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.1)\n",
      "Requirement already satisfied: h5py in /anaconda3/envs/learn-env/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "!brew install wget  # added by Miles\n",
    "!pip install --upgrade --ignore-installed wrapt  # added by Miles\n",
    "!pip install tensorflow==2.0.0-beta0  # modified by Miles: change to CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPHx8-t-VrVo"
   },
   "source": [
    "Begin by downloading the dataset. This tutorial uses a filtered version of <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs Cats</a> dataset from Kaggle. Download the archive version of the dataset and store it in the \"/tmp/\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpUSoFjuVrVp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-13 09:40:48--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.13.112\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.13.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68606236 (65M) [application/zip]\n",
      "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
      "\n",
      "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  17.2MB/s    in 4.3s    \n",
      "\n",
      "2019-06-13 09:40:53 (15.3 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "    -O /tmp/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lPjfOmNVrVs"
   },
   "source": [
    "Extract the dataset contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYmOylPlVrVt"
   },
   "outputs": [],
   "source": [
    "local_zip = '/tmp/cats_and_dogs_filtered.zip' # local path of downloaded .zip file\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp') # contents are extracted to '/tmp' folder\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Giv0wMQzVrVw"
   },
   "source": [
    "The dataset has the following directory structure:\n",
    "\n",
    "<pre>\n",
    "<b>cats_and_dogs_filtered</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
    "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
    "|__ <b>validation</b>\n",
    "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
    "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpmywIlsVrVx"
   },
   "source": [
    "After extracting its contents, assign variables with the proper file path for the training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRucI3QqVrVy"
   },
   "outputs": [],
   "source": [
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Utv3nryxVrV0"
   },
   "outputs": [],
   "source": [
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdrHHTy2VrV3"
   },
   "source": [
    "### Understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LblUYjl-VrV3"
   },
   "source": [
    "Let's look at how many cats and dogs images are in the training and validation directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc4u8e9hVrV4"
   },
   "outputs": [],
   "source": [
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "total_train = num_cats_tr + num_dogs_tr\n",
    "total_val = num_cats_val + num_dogs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4GGzGt0VrV7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 1000\n",
      "total training dog images: 1000\n",
      "total validation cat images: 500\n",
      "total validation dog images: 500\n",
      "--\n",
      "Total training images: 2000\n",
      "Total validation images: 1000\n"
     ]
    }
   ],
   "source": [
    "print('total training cat images:', num_cats_tr)\n",
    "print('total training dog images:', num_dogs_tr)\n",
    "\n",
    "print('total validation cat images:', num_cats_val)\n",
    "print('total validation dog images:', num_dogs_val)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdsI_L-NVrV_"
   },
   "source": [
    "# Set the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Lp-0ejxOtP1"
   },
   "source": [
    "For convenience, set up variables to use while pre-processing the dataset and training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NqNselLVrWA"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 15\n",
    "IMG_SHAPE = 150 # Our training data consists of images with width of 150 pixels and height of 150 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INn-cOn1VrWC"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Jfk6aSAVrWD"
   },
   "source": [
    "Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
    "\n",
    "1. Read images from the disk.\n",
    "2. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
    "3. Convert them into floating point tensors.\n",
    "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
    "\n",
    "Fortunately, all these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`. It can read images from disk and preprocess them into proper tensors. It will also set up generators that convert these images into batches of tensors—helpful when training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syDdF_LWVrWE"
   },
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLciCR_FVrWH"
   },
   "source": [
    "After defining the generators for training and validation images, the `flow_from_directory` method load images from the disk, applies rescaling, and resizes the images into the required dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pw94ajOOVrWI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     # Its usually best practice to shuffle the training data\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
    "                                                     class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2oUoKUzRVrWM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyexPJ8CVrWP"
   },
   "source": [
    "### Visualize training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60CnhEL4VrWQ"
   },
   "source": [
    "Visualize the training images by extracting a batch of images from the training generator—which is 32 images in this example—then plot five of them with `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f0Z7NZgVrWQ"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `array_to_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d1d7f8ee9a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_training_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    224\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         raise ImportError('Could not import PIL.Image. '\n\u001b[0m\u001b[1;32m    103\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[1;32m    104\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import PIL.Image. The use of `array_to_img` requires PIL."
     ]
    }
   ],
   "source": [
    "\n",
    "sample_training_images, _ = next(train_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49weMt5YVrWT"
   },
   "source": [
    "The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels. Discard the labels to only visualize the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMt2RES_VrWU"
   },
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_VVg_gEVrWW"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_training_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-dd13eeee46dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_training_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_training_images' is not defined"
     ]
    }
   ],
   "source": [
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5Ej-HLGVrWZ"
   },
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEgW4i18VrWZ"
   },
   "source": [
    "The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it thatr is activated by a `relu` activation function. The model outputs class probabilities based on binary classification by the `sigmoid` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F15-uwLPVrWa"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE, 3,)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PI5cdkMQVrWc"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "For this tutorial, choose the *ADAM* optimizer and *binary cross entropy* loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Mg7_TXOVrWd"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YmQZ3TAVrWg"
   },
   "source": [
    "### Model summary\n",
    "\n",
    "View all the layers of the network using the model's `summary` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vtny8hmBVrWh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               10617344  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 10,641,441\n",
      "Trainable params: 10,641,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N06iqE8VVrWj"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oub9RtoFVrWk"
   },
   "source": [
    "Use the `fit_generator` method of the `ImageDataGenerator` class to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSF2HqhDVrWk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `array_to_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f0c5403486df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_val\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(uid, i)\u001b[0m\n\u001b[1;32m    569\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mat\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mi\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m   \"\"\"\n\u001b[0;32m--> 571\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    224\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         raise ImportError('Could not import PIL.Image. '\n\u001b[0m\u001b[1;32m    103\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[1;32m    104\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import PIL.Image. The use of `array_to_img` requires PIL."
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(total_train / float(batch_size))),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(total_val / float(batch_size)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojJNteAGVrWo"
   },
   "source": [
    "### Visualize training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZPYT-EmVrWo"
   },
   "source": [
    "Now visualize the results after training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6oA77ADVrWp"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDnr50l2VrWu"
   },
   "source": [
    "As you can see from the plots, training accuracy and validation accuracy are off by large margin and the model has achieved only around **70%** accuracy on the validation set.\n",
    "\n",
    "Let's look at what went wrong and try to increase overall performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note (added by Miles): this is the end of the code-along\n",
    "# What we've learned: training a CNN from scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# << End of Code-Along >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note (added by Miles): the following is optional material\n",
    "# A better solution to this network's poor performance is to use transfer learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rLO7yhLlVrWu"
   },
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNyx3Lp4VrWv"
   },
   "source": [
    "In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 70% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable—a sign of *overfitting*.\n",
    "\n",
    "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples—to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
    "\n",
    "There are multiple ways to fight overfitting in the training process. In this tutorial, you'll use *data augmentation* and add *dropout* to our model.\n",
    "\n",
    "To begin, clear the previous Keras session and start a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_L8qd6IxVrWw"
   },
   "outputs": [],
   "source": [
    "# Clear resources\n",
    "tf.keras.backend.clear_session()\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOoVpxFwVrWy"
   },
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wn_QLciWVrWy"
   },
   "source": [
    "Overfitting generally occurs when there are a small number of training examples. One way to fix this problem is to augment the dataset so that it has a sufficient number of training examples. Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better.\n",
    "\n",
    "Implement this in `tf.keras` using the `ImageDataGenerator` class. Pass  different transformations to the dataset and it will take care of applying it during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uJ1G030VrWz"
   },
   "source": [
    "## Augment and visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvX7hHlgVrW0"
   },
   "source": [
    "Begin by applying random horizontal flip augmentation to the dataset and see how individual images look like after the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlVj6VqaVrW0"
   },
   "source": [
    "### Apply horizontal flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcdvx4TVVrW1"
   },
   "source": [
    "Pass `horizontal_flip` as an argument to the `ImageDataGenerator` class and set it to `True` to apply this augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bi1_vHyBVrW2"
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvwqmefgVrW3"
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(\n",
    "                                                batch_size=batch_size,\n",
    "                                                directory=train_dir,\n",
    "                                                shuffle=True,\n",
    "                                                target_size=(IMG_SHAPE,IMG_SHAPE)\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJpRSxJ-VrW7"
   },
   "source": [
    "Take one sample image from the training examples and repeat it five times so that the augmentation is applied to the same image five times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrKGd_jjVrW7"
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvBZoQ9xVrW9"
   },
   "outputs": [],
   "source": [
    "# Re-use the same custom plotting function defined and used\n",
    "# above to visualize the training images\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7n9xcqCVrXB"
   },
   "source": [
    "### Randomly rotate the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXnwkzFuVrXB"
   },
   "source": [
    "Let's take a look at a different augmentation called rotation and apply 45 degrees of rotation randomly to the training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zip35pDVrXB"
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVoWh4OIVrXD"
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(\n",
    "                                                batch_size=batch_size,\n",
    "                                                directory=train_dir,\n",
    "                                                shuffle=True,\n",
    "                                                target_size=(IMG_SHAPE, IMG_SHAPE)\n",
    "                                                )\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmBx8NhrVrXK"
   },
   "outputs": [],
   "source": [
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOqGPL76VrXM"
   },
   "source": [
    "### Apply zoom augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvqXaD8BVrXN"
   },
   "source": [
    "Apply a zoom augmentation to the dataset to zoom images up to 50% randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGNKLa_YVrXR"
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VOvTs32FVrXU"
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(\n",
    "                                                batch_size=batch_size,\n",
    "                                                directory=train_dir,\n",
    "                                                shuffle=True,\n",
    "                                                target_size=(IMG_SHAPE, IMG_SHAPE)\n",
    "                                                )\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KQWw8IZVrXZ"
   },
   "outputs": [],
   "source": [
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usS13KCNVrXd"
   },
   "source": [
    "### Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OC8fIsalVrXd"
   },
   "source": [
    "Apply all the previous augmentations. Here, you applied rescale, 45 degree rotation, width shift, height shift, horizontal flip and zoom augmentation to the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnr2xujaVrXe"
   },
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=45,\n",
    "                    width_shift_range=.15,\n",
    "                    height_shift_range=.15,\n",
    "                    horizontal_flip=True,\n",
    "                    zoom_range=0.5\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0Efxy7EVrXh"
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen_train.flow_from_directory(\n",
    "                                                batch_size=batch_size,\n",
    "                                                directory=train_dir,\n",
    "                                                shuffle=True,\n",
    "                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "                                                class_mode='binary'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AW-pV5awVrXl"
   },
   "source": [
    "Visualize how a single image would look five different times when passing these augmentations randomly to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2m68eMhVrXm"
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8cUd7FXVrXq"
   },
   "source": [
    "### Create validation data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a99fDBt7VrXr"
   },
   "source": [
    "Generally, only apply data augmentation to the training examples. In this case, only rescale the validation images and convert them into batches using `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54x0aNbKVrXr"
   },
   "outputs": [],
   "source": [
    "image_gen_val = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PCHKzI8VrXv"
   },
   "outputs": [],
   "source": [
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=validation_dir,\n",
    "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQGhdqHFVrXx"
   },
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Iq5TAH_VrXx"
   },
   "source": [
    "Another technique to reduce overfitting is to introduce *dropout* to the network. It is a form of *regularization* that forces the weights in the network to take only small values, which makes the distribution of weight values more regular and the network can reduce overfitting on small training examples. Dropout is one of the regularization technique used in this tutorial\n",
    "\n",
    "When you apply dropout to a layer it randomly drops out (set to zero) number of output units from the applied layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
    "\n",
    "When appling 0.1 dropout to a certain layer, it randomly kills 10% of the output units in each training epoch.\n",
    "\n",
    "Create a network architecture with this new dropout feature and apply it to different convolutions and fully-connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DyxxXRmVVrXy"
   },
   "source": [
    "# Creating a new network with Dropouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Ba2LjtkVrXy"
   },
   "source": [
    "Here, you apply dropout to first and last max pool layers and to a fully connected layer that has 512 output units. 30% of the first and last max pool layer, and 10% of fully connected layer output units, are randomly set to zero during each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fjio8EsVrXz"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 3, padding='same', activation='relu', input_shape=(150,150,3,)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpTgIxWAVrX0"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1osvc_iTVrX1"
   },
   "source": [
    "After introducing dropouts to the network, compile the model and view the layers summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkIJhS-WVrX1"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KiDshEUVrX6"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFj0oVqVVrX6"
   },
   "source": [
    "After successfully introducing data augmentations to the training examples and adding dropouts to the network, train this new network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GWxHs_luVrX7"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(total_train / float(batch_size))),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(total_val / float(batch_size)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbdyqZdxVrYA"
   },
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OgvF2nt7OtR7"
   },
   "source": [
    "Visualize the new model after training and see if there are signs of overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BTeMuNAVrYC"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrO5SdNoVrYH"
   },
   "source": [
    "### Evaluating the model\n",
    "\n",
    "As you can see, the model's learning curves are much better than before and there is much less overfitting. The model is able to achieve an accuracy of ~*75%*."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "LrO5SdNoVrYH"
   ],
   "name": "image_classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
